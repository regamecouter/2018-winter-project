{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8b873ccbb4649fe0ea803d217c0caa6235cb45c8"
   },
   "source": [
    "# PUBG Data Exploration + Random Forest (+ Funny GIFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1f9df06156beea9b9d45340f697e2b36e1923fde"
   },
   "source": [
    "[](http://)Hi fellow Kagglers! \n",
    "\n",
    "In this Kernel we ([Dalton Harmsen](https://www.kaggle.com/daltonharmsen), [Lourens Touwen](https://www.kaggle.com/lourenst) and [Carlo Lepelaars](https://www.kaggle.com/carlolepelaars)) will show you how we explore the [PUBG dataset](https://www.kaggle.com/c/pubg-finish-placement-prediction/data), detect outliers and recognize important features. We also implement a random forest model and optimize it.\n",
    "\n",
    "If you like this Kaggle kernel, feel free to give an upvote and leave a comment.\n",
    "\n",
    "A lot of inspiration for this kernel came from [fast.ai](https://www.fast.ai/)'s \"[Machine Learning for Coders](https://course.fast.ai/ml)\" course.\n",
    "\n",
    "![alt text](https://o.aolcdn.com/images/dims?quality=100&image_uri=http%3A%2F%2Fo.aolcdn.com%2Fhss%2Fstorage%2Fmidas%2Fb0be09f425cc5175fb413bc03c32dd0d%2F206235889%2Fpubg-ed.jpg&client=amp-blogside-v2&signature=88c6b77342cbeb0d25c0dc9d909018136aec1971 \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8f740329b056357ea730279df6227e870f8bfe97"
   },
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "941160a84b06865a8b6aabd63ffd26e0dc976919"
   },
   "source": [
    "* [Preparation](#1)\n",
    "* [Extra Data (Coming Soon)](#2)\n",
    "* [Initial Exploration](#3)\n",
    "* [Illegal Match](#4)\n",
    "* [Feature Engineering](#5)\n",
    "* [Outlier Detection](#6)\n",
    "* [Categorical Variables](#7)\n",
    "* [Preparation for Machine Learning](#8)\n",
    "* [Feature Importance](#9)\n",
    "* [Final Random Forest Model](#10)\n",
    "* [Kaggle Submission](#11)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4839fe8e33534748a73300cb4fda929e53cb084c"
   },
   "source": [
    "# Let's Go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0b4dc5ae4d6619691380e3371c8426ba19f75cdb"
   },
   "source": [
    "![Alt Text](https://media.giphy.com/media/xT9IgnOQS8e8uKkflK/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b23269c2d10ce96b38637524d88542a5eb620830"
   },
   "source": [
    "# Preparation <a id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a2db890615aad0e6bea09c06bf0c282569cdf659"
   },
   "source": [
    "First we import the dependencies needed for handling data, visualization and training our model. \n",
    "\n",
    "Important dependencies are:\n",
    "* [Pandas](https://pandas.pydata.org) for their dataframe structures and easy visualization.\n",
    "* [Matplotlib](https://matplotlib.org) for visualization.\n",
    "* [Scikit-learn](https://scikit-learn.org/stable) for machine learning.\n",
    "* [fastai](https://www.fast.ai) for machine learning and feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "bdeb441f12c31de6c12e4d9f058a3540edc17d2a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn_pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7ab59c6cf2c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m## This was copied from: https://github.com/anandsaha/fastai.part1.v2/blob/master/fastai/structured.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn_pandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFrameMapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImputer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mis_string_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_numeric_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn_pandas'"
     ]
    }
   ],
   "source": [
    "## Something went wrong when importing fastai.structured.\n",
    "## We fixed this by put the whole source code of fastai.structured in the notebook.\n",
    "## This was copied from: https://github.com/anandsaha/fastai.part1.v2/blob/master/fastai/structured.py\n",
    "\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer, StandardScaler\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype\n",
    "from sklearn.ensemble import forest\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "def get_sample(df,n):\n",
    "    \"\"\" Gets a random sample of n rows from df, without replacement.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas data frame, that you wish to sample from.\n",
    "    n: The number of rows you wish to sample.\n",
    "    Returns:\n",
    "    --------\n",
    "    return value: A random sample of n rows of df.\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "    >>> get_sample(df, 2)\n",
    "       col1 col2\n",
    "    2     3    a\n",
    "    1     2    b\n",
    "    \"\"\"\n",
    "    idxs = sorted(np.random.permutation(len(df))[:n])\n",
    "    return df.iloc[idxs].copy()\n",
    "\n",
    "def proc_df(df, y_fld, skip_flds=None, do_scale=False, na_dict=None,\n",
    "            preproc_fn=None, max_n_cat=None, subset=None, mapper=None):\n",
    "\n",
    "    \"\"\" proc_df takes a data frame df and splits off the response variable, and\n",
    "    changes the df into an entirely numeric dataframe.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: The data frame you wish to process.\n",
    "    y_fld: The name of the response variable\n",
    "    skip_flds: A list of fields that dropped from df.\n",
    "    do_scale: Standardizes each column in df,Takes Boolean Values(True,False)\n",
    "    na_dict: a dictionary of na columns to add. Na columns are also added if there\n",
    "        are any missing values.\n",
    "    preproc_fn: A function that gets applied to df.\n",
    "    max_n_cat: The maximum number of categories to break into dummy values, instead\n",
    "        of integer codes.\n",
    "    subset: Takes a random subset of size subset from df.\n",
    "    mapper: If do_scale is set as True, the mapper variable\n",
    "        calculates the values used for scaling of variables during training time(mean and standard deviation).\n",
    "    Returns:\n",
    "    --------\n",
    "    [x, y, nas, mapper(optional)]:\n",
    "        x: x is the transformed version of df. x will not have the response variable\n",
    "            and is entirely numeric.\n",
    "        y: y is the response variable\n",
    "        nas: returns a dictionary of which nas it created, and the associated median.\n",
    "        mapper: A DataFrameMapper which stores the mean and standard deviation of the corresponding continous\n",
    "        variables which is then used for scaling of during test-time.\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "    note the type of col2 is string\n",
    "    >>> train_cats(df)\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "    now the type of col2 is category { a : 1, b : 2}\n",
    "    >>> x, y, nas = proc_df(df, 'col1')\n",
    "    >>> x\n",
    "       col2\n",
    "    0     1\n",
    "    1     2\n",
    "    2     1\n",
    "    >>> data = DataFrame(pet=[\"cat\", \"dog\", \"dog\", \"fish\", \"cat\", \"dog\", \"cat\", \"fish\"],\n",
    "                 children=[4., 6, 3, 3, 2, 3, 5, 4],\n",
    "                 salary=[90, 24, 44, 27, 32, 59, 36, 27])\n",
    "    >>> mapper = DataFrameMapper([(:pet, LabelBinarizer()),\n",
    "                          ([:children], StandardScaler())])\n",
    "    >>>round(fit_transform!(mapper, copy(data)), 2)\n",
    "    8x4 Array{Float64,2}:\n",
    "    1.0  0.0  0.0   0.21\n",
    "    0.0  1.0  0.0   1.88\n",
    "    0.0  1.0  0.0  -0.63\n",
    "    0.0  0.0  1.0  -0.63\n",
    "    1.0  0.0  0.0  -1.46\n",
    "    0.0  1.0  0.0  -0.63\n",
    "    1.0  0.0  0.0   1.04\n",
    "    0.0  0.0  1.0   0.21\n",
    "    \"\"\"\n",
    "    if not skip_flds: skip_flds=[]\n",
    "    if subset: df = get_sample(df,subset)\n",
    "    df = df.copy()\n",
    "    if preproc_fn: preproc_fn(df)\n",
    "    y = df[y_fld].values\n",
    "    df.drop(skip_flds+[y_fld], axis=1, inplace=True)\n",
    "\n",
    "    if na_dict is None: na_dict = {}\n",
    "    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n",
    "    if do_scale: mapper = scale_vars(df, mapper)\n",
    "    for n,c in df.items(): numericalize(df, c, n, max_n_cat)\n",
    "    res = [pd.get_dummies(df, dummy_na=True), y, na_dict]\n",
    "    if do_scale: res = res + [mapper]\n",
    "    return res\n",
    "\n",
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)\n",
    "\n",
    "def set_rf_samples(n):\n",
    "    \"\"\" Changes Scikit learn's random forests to give each tree a random sample of\n",
    "    n random rows.\n",
    "    \"\"\"\n",
    "    forest._generate_sample_indices = (lambda rs, n_samples:\n",
    "        forest.check_random_state(rs).randint(0, n_samples, n))\n",
    "\n",
    "def reset_rf_samples():\n",
    "    \"\"\" Undoes the changes produced by set_rf_samples.\n",
    "    \"\"\"\n",
    "    forest._generate_sample_indices = (lambda rs, n_samples:\n",
    "        forest.check_random_state(rs).randint(0, n_samples, n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdpbox'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f57d48b81319>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpdpbox\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpdp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mplotnine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_summary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFrameSummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pdpbox'"
     ]
    }
   ],
   "source": [
    "# For autoreloading modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# For notebook plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pdpbox import pdp\n",
    "from plotnine import *\n",
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from IPython.display import display\n",
    "\n",
    "# Machine Learning\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from scipy.cluster import hierarchy as hc\n",
    "from fastai.imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e62dd6be42f75213328e57000fec73a88602dc19"
   },
   "source": [
    "And of course, we import our data from the Kaggle kernel directory and load it into two different DataFrames. one for the training data and one for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "a5857a23a06678f4c0f6456253b5bb40bbf45959"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../input/train_V2.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-24cf17373cc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Import dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mKAGGLE_DIR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../input/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKAGGLE_DIR\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'train_V2.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKAGGLE_DIR\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'test_V2.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'../input/train_V2.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "KAGGLE_DIR = '../input/'\n",
    "train = pd.read_csv(KAGGLE_DIR + 'train_V2.csv')\n",
    "test = pd.read_csv(KAGGLE_DIR + 'test_V2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5adc74a4fc2686a18c0997ece1e5c3c101f4900c"
   },
   "source": [
    "![API Img](http://media.comicbook.com/2018/03/pubg-api-1093349.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e3de60e57e0d325fdf13c926088f01434c310f25"
   },
   "source": [
    "# Initial Exploration <a id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "95e5306cf758cd8459afcffd6b7eb99ed4b9a189"
   },
   "source": [
    "Let's look at the DataFrame from head to tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9bd52fdce6397fd8ef147058f3315a188763b08b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2472c48b3e70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# First five rows (From Head)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'First 5 rows: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Last five rows (To Tail)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# First five rows (From Head)\n",
    "print('First 5 rows: ')\n",
    "display(train.head())\n",
    "\n",
    "# Last five rows (To Tail)\n",
    "print('Last 5 rows: ')\n",
    "display(train.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "81eb3f7644508d4b2a162ff6d12d586332660d4b"
   },
   "source": [
    "Summary Statistics of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "6b8ec8e0775e4b5933206f36245c0df9a9b8fa94"
   },
   "outputs": [],
   "source": [
    "# Stats\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fd9bc855bab51b675286a1403c5a9b8112d4a09d"
   },
   "source": [
    "Data types, memory usage, shape, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "8c67290aefc9ad3a87edee6bce1f6bf6fc8be11c"
   },
   "outputs": [],
   "source": [
    "# Types, Data points, memory usage, etc.\n",
    "train.info()\n",
    "\n",
    "# Check dataframe's shape\n",
    "print('Shape of training set: ', train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a13d786570e9e0d3d356236d90c1759523c570c3"
   },
   "source": [
    "### Feature descriptions (From Kaggle)\n",
    "\n",
    "* DBNOs - Number of enemy players knocked.\n",
    "* assists - Number of enemy players this player damaged that were killed by teammates.\n",
    "* boosts - Number of boost items used.\n",
    "* damageDealt - Total damage dealt. Note: Self inflicted damage is subtracted.\n",
    "* headshotKills - Number of enemy players killed with headshots.\n",
    "* heals - Number of healing items used.\n",
    "* Id - Player’s Id\n",
    "* killPlace - Ranking in match of number of enemy players killed.\n",
    "* killPoints - Kills-based external ranking of player. (Think of this as an Elo ranking where only kills matter.) If there is a value other than -1 in rankPoints, then any 0 in killPoints should be treated as a “None”.\n",
    "* killStreaks - Max number of enemy players killed in a short amount of time.\n",
    "* kills - Number of enemy players killed.\n",
    "* longestKill - Longest distance between player and player killed at time of death. This may be misleading, as downing a player and driving away may lead to a large longestKill stat.\n",
    "* matchDuration - Duration of match in seconds.\n",
    "* matchId - ID to identify match. There are no matches that are in both the training and testing set.\n",
    "* matchType - String identifying the game mode that the data comes from. The standard modes are “solo”, “duo”, “squad”, “solo-fpp”, “duo-fpp”, and “squad-fpp”; other modes are from events or custom matches.\n",
    "* rankPoints - Elo-like ranking of player. This ranking is inconsistent and is being deprecated in the API’s next version, so use with caution. Value of -1 takes place of “None”.\n",
    "* revives - Number of times this player revived teammates.\n",
    "* rideDistance - Total distance traveled in vehicles measured in meters.\n",
    "* roadKills - Number of kills while in a vehicle.\n",
    "* swimDistance - Total distance traveled by swimming measured in meters.\n",
    "* teamKills - Number of times this player killed a teammate.\n",
    "* vehicleDestroys - Number of vehicles destroyed.\n",
    "* walkDistance - Total distance traveled on foot measured in meters.\n",
    "* weaponsAcquired - Number of weapons picked up.\n",
    "* winPoints - Win-based external ranking of player. (Think of this as an Elo ranking where only winning matters.) If there is a value other than -1 in rankPoints, then any 0 in winPoints should be treated as a “None”.\n",
    "* groupId - ID to identify a group within a match. If the same group of players plays in different matches, they will have a different groupId each time.\n",
    "* numGroups - Number of groups we have data for in the match.\n",
    "* maxPlace - Worst placement we have data for in the match. This may not match with numGroups, as sometimes the data skips over placements.\n",
    "* winPlacePerc - The target of prediction. This is a percentile winning placement, where 1 corresponds to 1st place, and 0 corresponds to last place in the match. It is calculated off of maxPlace, not numGroups, so it is possible to have missing chunks in a match.\n",
    "\n",
    "[Source](https://www.kaggle.com/c/pubg-finish-placement-prediction/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7c2afb27c79156564dd3e947d64e072876507385"
   },
   "outputs": [],
   "source": [
    "# Use this code if you want to store and read DataFrames in a feather format\n",
    "# os.makedirs('tmp', exist_ok=True)\n",
    "# train.to_feather('tmp/PUBG')\n",
    "# df_raw = pd.read_feather('tmp/PUBG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c533098bd8e8c367885561ef0d516a71368a7eac"
   },
   "source": [
    "# Illegal Match <a id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2cb089208f1ac209c0fef999931b76e618e7424b"
   },
   "source": [
    "Fellow Kaggler '[averagemn](https://www.kaggle.com/donkeys)' brought to our attention that there is one particular player with a 'winPlacePerc' of NaN. The case was that this match had only one player. We will delete this row from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "76b2f1cd3305bc9fdd76ac0ccbc775e3bad4bae4"
   },
   "outputs": [],
   "source": [
    "# Check row with NaN value\n",
    "train[train['winPlacePerc'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "00818728e1a690831cb22d88ce9a96803190b164"
   },
   "source": [
    "Let's delete this entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "489f62b4ff01b527b72ea1112baaefea98bfe3c8"
   },
   "outputs": [],
   "source": [
    "# Drop row with NaN 'winPlacePerc' value\n",
    "train.drop(2744604, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4f3018a400a5990a4658722d9153a8e5e6f59830"
   },
   "source": [
    "And he's gone!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "32bdb55e3e06f70a0f3bbeac309c0c8ba21a396f"
   },
   "outputs": [],
   "source": [
    "# The row at index 2744604 will be gone\n",
    "train[train['winPlacePerc'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c15d5551a84dabff0d59ed84a6220adef302bc7e"
   },
   "source": [
    "# Feature Engineering <a id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c43a772690dc214d4064913c1ab1b1b61bce553e"
   },
   "source": [
    "Earlier in this kernel we created the new features ''totalDistance'' and  ''headshot_rate\". In this section we add more interesting features to improve the predictive quality of our machine learning models.\n",
    "\n",
    "Initial ideas for this section come from [this amazing kernel](https://www.kaggle.com/deffro/eda-is-fun).\n",
    "\n",
    "Note: It is important with feature engineering that you also add the engineered features to your test set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb73dd1d4f902c61fb7e52ad1f416a58d89a0c59"
   },
   "source": [
    "### Players Joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "14769f0996421ff43b39cf6d397130e79e336670"
   },
   "source": [
    "This is likely a very valuable feature for our model. If we know how many people are in a match we can normalize other features and get stronger predictions on individual players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7a75fe25d76011274b486440bcd5e26ec191c5b7"
   },
   "outputs": [],
   "source": [
    "# playersJoined\n",
    "train['playersJoined'] = train.groupby('matchId')['matchId'].transform('count')\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.countplot(train[train['playersJoined']>=75]['playersJoined'])\n",
    "plt.title('playersJoined')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "77953e661e4790bbc4b48a4ff77c2231d6d2c0a4"
   },
   "source": [
    "There are a few matches with fewer than 75 players that are not displayed here. As you can see most of the matches are nearly packed a have nearly 100 players. It is nevertheless interesting to take these features into our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4464ebc19a309d3f91a3f00cd3ae5e93523a6aac"
   },
   "source": [
    "### Normalized features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7e27723fa22ed3f5199ca04b38c6543951bd7503"
   },
   "source": [
    "Now that we have a feature 'playersJoined' we can normalize other features based on the amount of players. Features that can be valuable to normalize are:\n",
    "1. kills\n",
    "2. damageDealt\n",
    "3. maxPlace\n",
    "4. matchDuration\n",
    "\n",
    "Let's try out some things!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "db544668956444decf78a5f0f1ca1d38e86feafc"
   },
   "source": [
    "**Normalize features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4eab616403c996360579dd557f6384c15b195884"
   },
   "outputs": [],
   "source": [
    "# Create normalized features\n",
    "train['killsNorm'] = train['kills']*((100-train['playersJoined'])/100 + 1)\n",
    "train['damageDealtNorm'] = train['damageDealt']*((100-train['playersJoined'])/100 + 1)\n",
    "train['maxPlaceNorm'] = train['maxPlace']*((100-train['playersJoined'])/100 + 1)\n",
    "train['matchDurationNorm'] = train['matchDuration']*((100-train['playersJoined'])/100 + 1)\n",
    "# Compare standard features and normalized features\n",
    "to_show = ['Id', 'kills','killsNorm','damageDealt', 'damageDealtNorm', 'maxPlace', 'maxPlaceNorm', 'matchDuration', 'matchDurationNorm']\n",
    "train[to_show][0:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7218730f3ffea141c618d63126114e5e0ff240c8"
   },
   "source": [
    "### Heals and Boosts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "181836b3876b12e9b6cbf7c625c5825c9e33890a"
   },
   "source": [
    "We create a feature called 'healsandboosts' by adding heals and boosts. (duh!) We are not sure if this has additional predictive value, but we can always delete it later if the feature importance according to our random forest model is too low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c246ed0a7ad2497fbbf859b113aa60c1dea4a93f"
   },
   "outputs": [],
   "source": [
    "# Create new feature healsandboosts\n",
    "train['healsandboosts'] = train['heals'] + train['boosts']\n",
    "train[['heals', 'boosts', 'healsandboosts']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "51ea5401a88b9d8694da4d57a6b471de9e8a0a6f"
   },
   "source": [
    "### Killing without moving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9c74c8eff4c76b61e2923aa14e5c204047fcdb35"
   },
   "source": [
    "We try to identify cheaters by checking if people are getting kills without moving. We first identify the totalDistance travelled by a player and then set a boolean value to True if someone got kills without moving a single inch. We will remove cheaters in our outlier detection section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "262f7506c724ea2fdbea11ac9f9bb3dbc48d7ace"
   },
   "outputs": [],
   "source": [
    "# Create feature totalDistance\n",
    "train['totalDistance'] = train['rideDistance'] + train['walkDistance'] + train['swimDistance']\n",
    "# Create feature killsWithoutMoving\n",
    "train['killsWithoutMoving'] = ((train['kills'] > 0) & (train['totalDistance'] == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0519773b336f79d6b800d1f4df4ae0f6784ad1a7"
   },
   "source": [
    "The feature headshot_rate will also help us to catch cheaters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "98726a41b8b84b08ca12e851acbd895d6bf10de9"
   },
   "outputs": [],
   "source": [
    "# Create headshot_rate feature\n",
    "train['headshot_rate'] = train['headshotKills'] / train['kills']\n",
    "train['headshot_rate'] = train['headshot_rate'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2fd24975fea4672923a6f17b97d386d68dbc624e"
   },
   "source": [
    "# Outlier Detection <a id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "185e58dcca2c94699058cbecb578b66b8b9759bb"
   },
   "source": [
    "Some rows in our dataset have weird characteristics. The players could be cheaters, maniacs or just anomalies. Removing these outliers will likely improve results.\n",
    "\n",
    "Inspiration for this section comes from [this amazing Kaggle Kernel.](https://www.kaggle.com/rejasupotaro/cheaters-and-zombies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2fbfc8357d841d84d260037f462378a4220262ff"
   },
   "source": [
    "![Alt Text](https://media.giphy.com/media/OPRbXcsGctvZC/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0102793444dec610188263f49a6c62c6aee5d151"
   },
   "source": [
    "**Kills without movement**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d8e128346c856802b35fed1c0b4192f171e23f8e"
   },
   "source": [
    "This is perhaps the most obvious sign of cheating in the game. It is already fishy if a player hasn't moved during the whole game, but the player could be AFK and got killed. However, if the player managed to get kills without moving it is most likely a cheater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "da30e3cfe169d9565d1cfbe4e20b865599da8054"
   },
   "outputs": [],
   "source": [
    "# Check players who kills without moving\n",
    "display(train[train['killsWithoutMoving'] == True].shape)\n",
    "train[train['killsWithoutMoving'] == True].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8108bc1bc4d05f3f5caa52151849d9866a09a5ab"
   },
   "source": [
    "Got the suckers! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "348e477a90d2ff240daa54efd4a3e3859e2a88f6"
   },
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "train.drop(train[train['killsWithoutMoving'] == True].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4c0ba1b9a4b5b2365adfeca9724355dee62f887a"
   },
   "source": [
    "**Anomalies in roadKills**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f8f1ba0fac7a816f48574a3006c02e70d0208608"
   },
   "outputs": [],
   "source": [
    "# Players who got more than 10 roadKills\n",
    "train[train['roadKills'] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d1ec061ffe6ffef6613cb2de507a72c46327acac"
   },
   "outputs": [],
   "source": [
    "# Drop roadKill 'cheaters'\n",
    "train.drop(train[train['roadKills'] > 10].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "408338c1e3b18f4d9e4583e40c2be25fe1c4320f"
   },
   "source": [
    "Note that player c3e444f7d1289d drove 5 meters but killed 14 people with it. Sounds insane doesn't it?\n",
    "\n",
    "![Alt Text](https://media.giphy.com/media/3o7aD85usFbbbrCR3i/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "22481e8c1e188edcb0f6658fe0069526eb109e20"
   },
   "source": [
    "**Anomalies in aim (More than 45 kills)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8748b77ce33e88db23788147cae60d34a831ed0"
   },
   "source": [
    "Let's plot the total kills for every player first. It doesn't look like there are too many outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "388c2897e8d47785afa6ad8b4aa46e5e884eb624"
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of kills\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(data=train, x=train['kills']).set_title('Kills')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bc437ad16d8a267b01fd437b521b011d57787c0e"
   },
   "source": [
    "Let's take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b840338f2874be2d6365127dd017e05c167cabfa"
   },
   "outputs": [],
   "source": [
    "# Players who got more than 30 kills\n",
    "display(train[train['kills'] > 30].shape)\n",
    "train[train['kills'] > 30].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d7b37bfae4e8fec8ac422f2e767c4fa8dcfd7846"
   },
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "train.drop(train[train['kills'] > 30].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "94f2181a2fbaf64a9cf6a4453b2aeabc90f05c1f"
   },
   "source": [
    "What do you think? Should we remove all these outliers from our dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "219bbd2899ea6d0f70e8a568252cc9dba6ff3e67"
   },
   "source": [
    "**Anomalies in aim part 2 (100% headshot rate)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2b9cd4f806e2979c690cc34a0de54ecf286cefb9"
   },
   "source": [
    "Again, we first take a look at the whole dataset and create a new feature 'headshot_rate'.\n",
    "We see that the most players score in the 0 to 10% region. However, there are a few anomalies that have a headshot_rate of 100% percent with more than 9 kills!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "22896da322fea9b8217a6074477dbaa45f842717"
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of headshot_rate\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.distplot(train['headshot_rate'], bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "6a003de33fc1558b86a9b05d2e1b1bf969f6d65f"
   },
   "outputs": [],
   "source": [
    "# Players who made a minimum of 10 kills and have a headshot_rate of 100%\n",
    "display(train[(train['headshot_rate'] == 1) & (train['kills'] > 9)].shape)\n",
    "train[(train['headshot_rate'] == 1) & (train['kills'] > 9)].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ce429d895b64c622d0ea2d9386b89fd4dc2649b6"
   },
   "source": [
    "It is unclear if these players are cheating so we are probably not deleting these players from the dataset.\n",
    "If they are legitimate players, they are probably really crushing the game!\n",
    "\n",
    "![Alt Text](https://media.giphy.com/media/l3mZrOajz5VCZf7Hy/giphy.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2b7505e30aff6bcf102cd2a6a2b536b4c2cb11d1"
   },
   "source": [
    "**Anomalies in aim part 3 (Longest kill)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c21394d6f48e92ec4f323415127e62f6c4393f6"
   },
   "source": [
    "Most kills are made from a distance of 100 meters or closer. There are however some outliers who make a kill from more than 1km away. This is probably done by cheaters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "dfea1244b10c7165c450e919a64285c2b43ece61"
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of longestKill\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.distplot(train['longestKill'], bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8a8e8c469da8f100fb775654db8981e994f82cef"
   },
   "source": [
    "Let's take a look at the players who make these shots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "dcef65eabf244dff8c64396be90d5d59ac230f68"
   },
   "outputs": [],
   "source": [
    "# Check out players who made kills with a distance of more than 1 km\n",
    "display(train[train['longestKill'] >= 1000].shape)\n",
    "train[train['longestKill'] >= 1000].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f833cad4928a7892666aad196a5ee4fc50f430e2"
   },
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "train.drop(train[train['longestKill'] >= 1000].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "adfda3cd3309bf8da86d40d33245a7e630be4907"
   },
   "source": [
    "There is something fishy going on with these players. We are probably better off removing them from our dataset.\n",
    "\n",
    "![Alt Text](https://media.giphy.com/media/RHJkLqcdvMQF4GI3P7/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "be486cb9e83fb176c2ab3417f55ea3c0d74f49e6"
   },
   "source": [
    "**Anomalies in travelling (rideDistance, walkDistance and swimDistance)**\n",
    "\n",
    "Let's check out anomalies in Distance travelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "a0d5a4921c19aae8d93e9d80c62c0803896c93bb"
   },
   "outputs": [],
   "source": [
    "# Summary statistics for the Distance features\n",
    "train[['walkDistance', 'rideDistance', 'swimDistance', 'totalDistance']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "403d65810b9e9dc4c6c4495e07451823ba59f2a6"
   },
   "source": [
    "**walkDistance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4f4fb06011ba1e65e4cb8cd805a64da10e9e2283"
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of walkDistance\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.distplot(train['walkDistance'], bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "8cdc0e3d4a14fdf51aab64a380a311a5cdbcbe42"
   },
   "outputs": [],
   "source": [
    "# walkDistance anomalies\n",
    "display(train[train['walkDistance'] >= 10000].shape)\n",
    "train[train['walkDistance'] >= 10000].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "0d71a994fd557c9d7d71dd4478d0d09b3b127402"
   },
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "train.drop(train[train['walkDistance'] >= 10000].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ee7416643d8b9036404567df7608a77605ee06c5"
   },
   "source": [
    "**rideDistance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1460a9d8d4892157d05dc399b246bd50d130a97f"
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of rideDistance\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.distplot(train['rideDistance'], bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "6fc29ab53d5d27e8314dda6b6573d45d3419b8c5"
   },
   "outputs": [],
   "source": [
    "# rideDistance anomalies\n",
    "display(train[train['rideDistance'] >= 20000].shape)\n",
    "train[train['rideDistance'] >= 20000].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7d78cb510ae3e35b3b8cedd4cf700aafe13583c6"
   },
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "train.drop(train[train['rideDistance'] >= 20000].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3580e00d15ff02a686921640ac50bc90650004f3"
   },
   "source": [
    "Cheaters or do they just like to ride like these guys?\n",
    "\n",
    "![Alt Text](https://media.giphy.com/media/qlCFjkSruesco/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4d708353553b12aa60214fd09c6555d6b1052696"
   },
   "source": [
    "**swimDistance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f868aa417c9f9408a8275a38815887b9fb652230"
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of swimDistance\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.distplot(train['swimDistance'], bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9442e76cdcc02f1e8478de77e263bb71f294900a"
   },
   "outputs": [],
   "source": [
    "# Players who swam more than 2 km\n",
    "train[train['swimDistance'] >= 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "259b8a3320dd6fa378807ba91bd68b90893c8b90"
   },
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "train.drop(train[train['swimDistance'] >= 2000].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f0638e64dd53238885c855cbfcde90576b2bce72"
   },
   "source": [
    "Do you think these guys are legit?\n",
    "\n",
    "![Alt Text](https://thumbs.gfycat.com/EvenSpiffyFerret-size_restricted.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "747c3f2289db22d0fd79faf4ef094e7ec5c65a2b"
   },
   "source": [
    "**Anomalies in supplies (weaponsAcquired)**\n",
    "\n",
    "Most people acquire between 0 and 10 weapons in a game, but you also see some people acquire more than 80 weapons! Let's check these guys out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d6b31e6cd3c4e399f9bd913d2a427e8a6c05f75f"
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of weaponsAcquired\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.distplot(train['weaponsAcquired'], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f018c4a79a6bbf8bed1aa657854d8ceaf3126839"
   },
   "outputs": [],
   "source": [
    "# Players who acquired more than 80 weapons\n",
    "display(train[train['weaponsAcquired'] >= 80].shape)\n",
    "train[train['weaponsAcquired'] >= 80].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4954a532da109a59999492674762f388781d1ab6"
   },
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "train.drop(train[train['weaponsAcquired'] >= 80].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "968b40a40387c2be3be403dc8b78bd3c073ceee1"
   },
   "source": [
    "We should probably remove these outliers from our model. Do you agree?\n",
    "\n",
    "Note that player 3f2bcf53b108c4 acquired 236 weapons in one game!\n",
    "\n",
    "![Alt Text](https://media.giphy.com/media/69lWR6c8Afx9qeg2Tu/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0e2afc8a8abd8d9f5dc512d8568469ae096d298"
   },
   "source": [
    "**Anomalies in supplies part 2 (heals)**\n",
    "\n",
    "Most players us 5 healing items or less. We can again recognize some weird anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c35982212815e05e2c4cbef09cc805ad0afcf8c1"
   },
   "outputs": [],
   "source": [
    "# Distribution of heals\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.distplot(train['heals'], bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "adb9816d04fed2d3bc492c7795d25624ee1bf6c8"
   },
   "outputs": [],
   "source": [
    "# 40 or more healing items used\n",
    "display(train[train['heals'] >= 40].shape)\n",
    "train[train['heals'] >= 40].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1435be82713069ee3a04245157f33d640bc9e141"
   },
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "train.drop(train[train['heals'] >= 40].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8372a45ffb2e55801094d919babb130d704351ee"
   },
   "source": [
    "**Outlier conclusions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3d4b73bec9e3e3d2116a0330aa6b545d408389b1"
   },
   "source": [
    "We removed about 2000 players from our dataset. Do you think this is too much? Please let us know in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c10aed82e0d5afbda0f9989cc84c072034d618cf"
   },
   "outputs": [],
   "source": [
    "# Remaining players in the training set\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c256f1f1c4a45cc97e4b5a7be99865c1f528f2e3"
   },
   "source": [
    "# Categorical Variables <a id=\"7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5dcbdd5c6d1ebfbc14848b9829e47823f12c105b"
   },
   "source": [
    "We will one hot encode the 'matchType' feature to use it in our Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "510bcf385c79a92d9152377a952af78ce9cafcfd"
   },
   "outputs": [],
   "source": [
    "print('There are {} different Match types in the dataset.'.format(train['matchType'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b5a729fc92482307c171dfd788b546f1154c0b1c"
   },
   "outputs": [],
   "source": [
    "# One hot encode matchType\n",
    "train = pd.get_dummies(train, columns=['matchType'])\n",
    "\n",
    "# Take a look at the encoding\n",
    "matchType_encoding = train.filter(regex='matchType')\n",
    "matchType_encoding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8382ed80c5307282913325c4a6fe90b833cdd2e3"
   },
   "source": [
    "There are a lot of groupId's and matchId's so one-hot encoding them is computational suicide.\n",
    "We will turn them into category codes. That way we can still benefit from correlations between groups and matches in our Random Forest algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "133123c3b9d5d398c9bb4d62fdebde0d65c240ba"
   },
   "outputs": [],
   "source": [
    "# Turn groupId and match Id into categorical types\n",
    "train['groupId'] = train['groupId'].astype('category')\n",
    "train['matchId'] = train['matchId'].astype('category')\n",
    "\n",
    "# Get category coding for groupId and matchID\n",
    "train['groupId_cat'] = train['groupId'].cat.codes\n",
    "train['matchId_cat'] = train['matchId'].cat.codes\n",
    "\n",
    "# Get rid of old columns\n",
    "train.drop(columns=['groupId', 'matchId'], inplace=True)\n",
    "\n",
    "# Lets take a look at our newly created features\n",
    "train[['groupId_cat', 'matchId_cat']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9ceab55a2e10123e8d59855c24d49a314e8cce07"
   },
   "outputs": [],
   "source": [
    "# Drop Id column, because it probably won't be useful for our Machine Learning algorithm,\n",
    "# because the test set contains different Id's\n",
    "train.drop(columns = ['Id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "05b1072b5788914c05bea01ed3725f6862beabca"
   },
   "source": [
    "**voilà!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b0cf78cccb5e01bbe8aa155db5dc4d9df175352b"
   },
   "source": [
    "# Preparation for Machine Learning <a id=\"8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4d585439ad63102cce6dac9801d1fd1e9e7fab03"
   },
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8cd476a71251ba0d0592e9f2bb7972dfd1dac6d4"
   },
   "source": [
    "We will take a sample of 500000 rows from our training set for easy debugging and exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f314c6b60c814bebbffd36946f0fabb572de384a"
   },
   "outputs": [],
   "source": [
    "# Take sample for debugging and exploration\n",
    "sample = 500000\n",
    "df_sample = train.sample(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "78f2dea8253ffa5ada2797b0cf49c0eb83513bd0"
   },
   "source": [
    "## Split target variable, validation data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b186279f329752b77f26d523095d89b493fcfd22"
   },
   "outputs": [],
   "source": [
    "# Split sample into training data and target variable\n",
    "df = df_sample.drop(columns = ['winPlacePerc']) #all columns except target\n",
    "y = df_sample['winPlacePerc'] # Only target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1b9e944106ee40c231d60b9056bc841eed180405"
   },
   "outputs": [],
   "source": [
    "# Function for splitting training and validation data\n",
    "def split_vals(a, n : int): \n",
    "    return a[:n].copy(), a[n:].copy()\n",
    "val_perc = 0.12 # % to use for validation set\n",
    "n_valid = int(val_perc * sample) \n",
    "n_trn = len(df)-n_valid\n",
    "# Split data\n",
    "raw_train, raw_valid = split_vals(df_sample, n_trn)\n",
    "X_train, X_valid = split_vals(df, n_trn)\n",
    "y_train, y_valid = split_vals(y, n_trn)\n",
    "\n",
    "# Check dimensions of samples\n",
    "print('Sample train shape: ', X_train.shape, \n",
    "      'Sample target shape: ', y_train.shape, \n",
    "      'Sample validation shape: ', X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d8c3d9e3f5efd4040a32ddf047406fa17a3dad7"
   },
   "source": [
    "## Set metrics (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3506f00e6c842edfcdbd67fdd315dbff2258f679"
   },
   "source": [
    "[Mean Absolute Error (MAE)](https://en.wikipedia.org/wiki/Mean_absolute_error) is the metric that is used for this competition. The scikit-learn library already programmed this metric for us so we don't have to implement it from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7dee35b5298eb55750e4e338439be5c8b13acd0f"
   },
   "outputs": [],
   "source": [
    "# Metric used for the PUBG competition (Mean Absolute Error (MAE))\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function to print the MAE (Mean Absolute Error) score\n",
    "# This is the metric used by Kaggle in this competition\n",
    "def print_score(m : RandomForestRegressor):\n",
    "    res = ['mae train: ', mean_absolute_error(m.predict(X_train), y_train), \n",
    "           'mae val: ', mean_absolute_error(m.predict(X_valid), y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e6ec67f2a1507fc9af1131ade377c4058bd580a6"
   },
   "source": [
    "## First basic Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d4489216c4511111d67ae7f492fde6bf8e78930e"
   },
   "outputs": [],
   "source": [
    "# Train basic model\n",
    "m1 = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features='sqrt',\n",
    "                          n_jobs=-1)\n",
    "m1.fit(X_train, y_train)\n",
    "print_score(m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a6f61fcbf672cfba905b99cc781ac3e8a648be89"
   },
   "source": [
    "# Feature Importance <a id=\"9\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c0b10cfc2d99ee8f1db4d0b36cf5e95bfe0e0505"
   },
   "source": [
    "The [fastai](https://www.fast.ai/) library gives us an easy way to analyze feature importances from a random forest algorithm with just one line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ed5518de78d258cb9e48b9eaf7181505a26422ce"
   },
   "outputs": [],
   "source": [
    "# What are the most predictive features according to our basic random forest model\n",
    "fi = rf_feat_importance(m1, df); fi[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9d4f1ee82e91edcf21ae642f2b31e47220fa25b5"
   },
   "outputs": [],
   "source": [
    "# Plot a feature importance graph for the 20 most important features\n",
    "plot1 = fi[:20].plot('cols', 'imp', figsize=(14,6), legend=False, kind = 'barh')\n",
    "plot1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b3488ed05503ce0c4f7bc6ce4b188e919638a8c0"
   },
   "outputs": [],
   "source": [
    "# Use this code if you want to save the figure\n",
    "#fig = plot1.get_figure()\n",
    "#fig.savefig(\"Feature_importances(AllFeatures).png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d6e9ba1de99350eb23ee62bd837d7305e73cceae"
   },
   "outputs": [],
   "source": [
    "# Keep only significant features\n",
    "to_keep = fi[fi.imp>0.005].cols\n",
    "print('Significant features: ', len(to_keep))\n",
    "to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c1f1f3709fa7734c55c89a1636ee9f36de2d33bf"
   },
   "outputs": [],
   "source": [
    "# Make a DataFrame with only significant features\n",
    "df_keep = df[to_keep].copy()\n",
    "X_train, X_valid = split_vals(df_keep, n_trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2ed0c240276e2d14f5fa15fe5f6161902036a3b0"
   },
   "source": [
    "## Second Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "696de3de3da7f1c457004b32ddf0c9f34a3ae7ea"
   },
   "source": [
    "This time we use only the top features to train a random forest model. This often improves results a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f43327039dd653fdc1b9667bc9179dbb33e94bbe"
   },
   "outputs": [],
   "source": [
    "# Train model on top features\n",
    "m2 = RandomForestRegressor(n_estimators=80, min_samples_leaf=3, max_features='sqrt',\n",
    "                          n_jobs=-1)\n",
    "m2.fit(X_train, y_train)\n",
    "print_score(m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dde32bf21cb7471d76710cf32dbccf3d9530e50a"
   },
   "source": [
    "**Feature importance for top features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "95abd55e65be6e2cbf68d8f20320e48c934b9ce3"
   },
   "outputs": [],
   "source": [
    "# Get feature importances of our top features\n",
    "fi_to_keep = rf_feat_importance(m2, df_keep)\n",
    "plot2 = fi_to_keep.plot('cols', 'imp', figsize=(14,6), legend=False, kind = 'barh')\n",
    "plot2\n",
    "\n",
    "# Use this code if you want to save the figure\n",
    "#fig = plot2.get_figure()\n",
    "#fig.savefig(\"Feature_importances(TopFeatures).png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "94a53c9d4ebec27addb85d905d327f9fbbbe2a5c"
   },
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8ace9ff753eb84346d4eb833a084a8c26e90403b"
   },
   "source": [
    "**Dendrogram (to view correlation of features)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "6649d9a0c95888f47f1ce0e28d9dcd332068fb30"
   },
   "outputs": [],
   "source": [
    "# Create a Dendrogram to view highly correlated features\n",
    "corr = np.round(scipy.stats.spearmanr(df_keep).correlation, 4)\n",
    "corr_condensed = hc.distance.squareform(1-corr)\n",
    "z = hc.linkage(corr_condensed, method='average')\n",
    "fig = plt.figure(figsize=(14,10))\n",
    "dendrogram = hc.dendrogram(z, labels=df_keep.columns, orientation='left', leaf_font_size=16)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "febcb7637e18d6195c62abfb11eef5a4129b4264"
   },
   "outputs": [],
   "source": [
    "# Use this code if you want to save the figure\n",
    "#plt.savefig('Dendrogram.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "50dcfbf77e572dcf7e05a0546842d5b488c51ad0"
   },
   "source": [
    "**Correlation Heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "55165f98d16525caa9338355c429f0234e9a0504"
   },
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "corr = df_keep.corr()\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Create heatmap\n",
    "heatmap = sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "17afed7802e5aa88ba007fa4449ec14ddc90e3e9"
   },
   "outputs": [],
   "source": [
    "# Use this code if you want to save the figure\n",
    "#fig = heatmap.get_figure()\n",
    "#fig.savefig(\"Heatmap(TopFeatures).png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f70fb918e231398b80cb85c5f1e029c3eb878040"
   },
   "source": [
    "**Predictive quality of kills**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "3edecb00b13b3080e2dec056859389e91a4a2c6c"
   },
   "outputs": [],
   "source": [
    "# Plot the predictive quality of kills \n",
    "x_all = get_sample(train, 100000)\n",
    "ggplot(x_all, aes('kills','winPlacePerc'))+stat_smooth(se=True, colour='red', method='mavg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a3113938505d569f5fb8a35e1efd3530dd035fa5"
   },
   "source": [
    "**Predictive quality of walkDistance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "81d653d698297d0389e3f1585bd7fcaeafab5d8c"
   },
   "outputs": [],
   "source": [
    "# Plot the predictive quality of walkDistance\n",
    "x_all = get_sample(train, 100000)\n",
    "ggplot(x_all, aes('walkDistance','winPlacePerc'))+stat_smooth(se=True, colour='red', method='mavg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fdfca397c21dcf8980fe8589b951eb1439bc9b6e"
   },
   "source": [
    "# Final Random Forest Model <a id=\"10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d50536ab9f59e5e9d7d027b2eea7786d4b544d51"
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "val_perc_full = 0.12 # % to use for validation set\n",
    "n_valid_full = int(val_perc_full * len(train)) \n",
    "n_trn_full = len(train)-n_valid_full\n",
    "df_full = train.drop(columns = ['winPlacePerc']) # all columns except target\n",
    "y = train['winPlacePerc'] # target variable\n",
    "df_full = df_full[to_keep] # Keep only relevant features\n",
    "X_train, X_valid = split_vals(df_full, n_trn_full)\n",
    "y_train, y_valid = split_vals(y, n_trn_full)\n",
    "\n",
    "# Check dimensions of data\n",
    "print('Sample train shape: ', X_train.shape, \n",
    "      'Sample target shape: ', y_train.shape, \n",
    "      'Sample validation shape: ', X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "34e6a7dbd3ad84aa210305a4bbb1775250a579d3"
   },
   "outputs": [],
   "source": [
    "# Train final model\n",
    "# You should get better results by increasing n_estimators\n",
    "# and by playing around with the parameters\n",
    "m3 = RandomForestRegressor(n_estimators=70, min_samples_leaf=3, max_features=0.5,\n",
    "                          n_jobs=-1)\n",
    "m3.fit(X_train, y_train)\n",
    "print_score(m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ce411182dbe027528b4a12322fcdae458fe32fbc"
   },
   "source": [
    "# Kaggle Submission <a id=\"11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "72ed9b8e81fbff544be0c1dbf1772ef21eb98d84"
   },
   "outputs": [],
   "source": [
    "# Add engineered features to the test set\n",
    "test['headshot_rate'] = test['headshotKills'] / test['kills']\n",
    "test['headshot_rate'] = test['headshot_rate'].fillna(0)\n",
    "test['totalDistance'] = test['rideDistance'] + test['walkDistance'] + test['swimDistance']\n",
    "test['playersJoined'] = test.groupby('matchId')['matchId'].transform('count')\n",
    "test['killsNorm'] = test['kills']*((100-test['playersJoined'])/100 + 1)\n",
    "test['damageDealtNorm'] = test['damageDealt']*((100-test['playersJoined'])/100 + 1)\n",
    "test['maxPlaceNorm'] = test['maxPlace']*((100-train['playersJoined'])/100 + 1)\n",
    "test['matchDurationNorm'] = test['matchDuration']*((100-test['playersJoined'])/100 + 1)\n",
    "test['healsandboosts'] = test['heals'] + test['boosts']\n",
    "test['killsWithoutMoving'] = ((test['kills'] > 0) & (test['totalDistance'] == 0))\n",
    "\n",
    "# Turn groupId and match Id into categorical types\n",
    "test['groupId'] = test['groupId'].astype('category')\n",
    "test['matchId'] = test['matchId'].astype('category')\n",
    "\n",
    "# Get category coding for groupId and matchID\n",
    "test['groupId_cat'] = test['groupId'].cat.codes\n",
    "test['matchId_cat'] = test['matchId'].cat.codes\n",
    "\n",
    "# Remove irrelevant features from the test set\n",
    "test_pred = test[to_keep].copy()\n",
    "\n",
    "# Fill NaN with 0 (temporary)\n",
    "test_pred.fillna(0, inplace=True)\n",
    "test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "91705fe1eda0ce7a0d710c9dffce0c0c3557550a"
   },
   "outputs": [],
   "source": [
    "# Make submission ready for Kaggle\n",
    "# We use our final Random Forest model (m3) to get the predictions\n",
    "predictions = np.clip(a = m3.predict(test_pred), a_min = 0.0, a_max = 1.0)\n",
    "pred_df = pd.DataFrame({'Id' : test['Id'], 'winPlacePerc' : predictions})\n",
    "\n",
    "# Create submission file\n",
    "pred_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c765862512bbfad85c3ddb53b1c6f624ffe52fd3"
   },
   "source": [
    "**Check of submission file**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d1151332ec65e2902fc32ad8f024400b1faa0ed0"
   },
   "source": [
    "It is always nice to take a look at few of your predictions to make sure that the structure is right for a Kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "a1c2f4850afe7346b37e9336e7524cad402a63d3"
   },
   "outputs": [],
   "source": [
    "# Last check of submission\n",
    "print('Head of submission: ')\n",
    "display(pred_df.head())\n",
    "print('Tail of submission: ')\n",
    "display(pred_df.tail())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
